# -*- coding: utf-8 -*-
"""06_SSI_Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iwGfqR0fIAQC1m2fB_1ZL8EDWAPgzBcN

pip install git+https://github.com/MDCHAMP/hawk-data
"""

# 1. Monter Google Drive (ex√©cute cette cellule une fois au d√©but)
from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
import seaborn as sns
from scipy.spatial.distance import mahalanobis
from scipy.signal import find_peaks
import pickle

plt.rcParams['savefig.dpi'] = 300
sns.set_theme("paper")
sns.set_style("ticks")
sns.set_palette("Set2")
"""
data_dir = "./hawk_data"
data = FST(data_dir)
"""

# Contr√¥le si les figures doivent √™tre sauvegard√©es
save = True
save_dir = './figures/'

"""test_id = 'DS_WN'
test_numbers = [
    '01', '02', '03', '19', '20', '21', '64', '65', '66',
    '04', '05', '06', '22', '23', '24', '67', '68', '69',
    '07', '08', '09', '25', '26', '27', '70', '71', '72'
]

for test_number in test_numbers:
    test_series = data[f'{test_id}/{test_number}']

test_id = 'HS_WN'
test_numbers = [
    '01', '02', '03', '04', '05'
]

for test_number in test_numbers:
    test_series = data[f'{test_id}/{test_number}']

## √©tape 1 : d√©coupage par segments

# d√©coupage par segments
fbg_caps = [f"SW_FB{i}" for i in range(1, 11)]
fs = 2048  # Fr√©quence d'√©chantillonnage (Hz)
segment_duration = 1  # Dur√©e de segment en secondes
segment_length = fs * segment_duration  # 2048
n_segments = 80  # Car signaux de 80 secondes

# Dictionnaire final contenant les segments pour tous les tests et capteurs
segments_fbg = {}

tests_par_classe = {
    "HS": [
        "HS_WN/01", "HS_WN/02", "HS_WN/03", "HS_WN/04", "HS_WN/05"
    ],
    "DS_CTE": [
        "DS_WN/01", "DS_WN/02", "DS_WN/03", "DS_WN/19", "DS_WN/20", "DS_WN/21", "DS_WN/64", "DS_WN/65", "DS_WN/66"
    ],
    "DS_RLE": [
        "DS_WN/04", "DS_WN/05", "DS_WN/06", "DS_WN/22", "DS_WN/23", "DS_WN/24", "DS_WN/67", "DS_WN/68", "DS_WN/69"
    ],
    "DS_TLE": [
        "DS_WN/07", "DS_WN/08", "DS_WN/09", "DS_WN/25", "DS_WN/26", "DS_WN/27", "DS_WN/70", "DS_WN/71", "DS_WN/72"
    ]
}

start_idx = int(0.05 * 163840)   # 8192
end_idx = int(0.95 * 163840)     # 155648
usable_length = end_idx - start_idx  # 147456
segment_length = 2048
n_segments = usable_length // segment_length  # 72 segments

segments_fbg = {}

for classe, test_list in tests_par_classe.items():
    segments_fbg[classe] = {}

    for test_path in test_list:
        test_id, test_number = test_path.split("/")
        segments_fbg[classe][test_path] = {}

        for capteur in fbg_caps:
            strain = data[test_id][test_number][capteur]["strain"][:]
            signal = np.mean(strain, axis=1)
            signal = signal - np.mean(signal)

            # Coupe la partie utile seulement (centrale : 5% √† 95%)
            signal_util = signal[start_idx:end_idx]

            segments = [
                signal_util[i * segment_length : (i + 1) * segment_length]
                for i in range(n_segments)
            ]

            segments_fbg[classe][test_path][capteur] = segments

# V√©rifie la taille du fichier
import os
os.path.getsize("/content/drive/MyDrive/segments_fbg.pkl")

# supprimer un fichier
!rm /content/drive/MyDrive/ssi_segmental.pkl

import pickle

with open("/content/drive/MyDrive/segments_fbg.pkl", "wb") as f:
    pickle.dump(segments_fbg, f)

## √âtape 2 ‚Äì G√©n√©ration de split_segments.pkl

# g√©n√©rer le split 70/15/15 par segment

import pickle
import random

# Charger les segments (1 s)
with open("/content/drive/MyDrive/segments_fbg.pkl", "rb") as f:
    segments_fbg = pickle.load(f)

split_segments = {}
random.seed(42)  # üîí Pour reproductibilit√©

for classe, tests in segments_fbg.items():
    split_segments[classe] = {}

    for test_path, capteurs in tests.items():
        split_segments[classe][test_path] = {}

        for capteur, segments in capteurs.items():
            n = len(segments)  # En g√©n√©ral : 72 segments de 1 s
            indices = list(range(n))
            random.shuffle(indices)

            # D√©coupe 70/15/15
            n_train = int(0.7 * n)
            n_val = int(0.15 * n)
            n_test = n - n_train - n_val  # pour compl√©ter √† n

            tags = ["train"] * n_train + ["val"] * n_val + ["test"] * n_test

            # R√©attribuer les tags aux bons indices
            tag_array = [None] * n
            for idx, tag in zip(indices, tags):
                tag_array[idx] = tag

            split_segments[classe][test_path][capteur] = tag_array

with open("/content/drive/MyDrive/split_segments.pkl", "wb") as f:
    pickle.dump(split_segments, f)

print("‚úÖ split_segments.pkl sauvegard√© avec succ√®s dans ton Drive.")

from collections import Counter

ex = split_segments["HS"]["HS_WN/01"]["SW_FB3"]
Counter(ex)  # ‚Üí ex: Counter({'train': 50, 'val': 11, 'test': 11})

## √âtape 3 : T√©l√©charger et charger FFDNet

# Fonction : generate_cwt_image_ffdnet
import os
import numpy as np
import pywt
import torch
from skimage.transform import resize
from PIL import Image

def generate_cwt_image_ffdnet(segment, split, classe, test_path, capteur, index, output_base, model, device):

    G√©n√®re et sauvegarde une image CWT 224x224 d√©bruit√©e par FFDNet √† partir d‚Äôun segment 1D.

    Args:
        segment (np.array): signal 1D de 2048 points
        split (str): 'train', 'val' ou 'test'
        classe (str): 'HS', 'DS_CTE', etc.
        test_path (str): ex: 'DS_WN/01'
        capteur (str): ex: 'SW_FB2'
        index (int): num√©ro du segment dans la s√©quence
        output_base (str): chemin de base du dossier de sortie, ex: '/content/drive/MyDrive/CWT_images'
        model (torch.nn.Module): mod√®le FFDNet
        device (torch.device): CUDA ou CPU

    # Param√®tres
    img_size = 224
    scales = np.arange(1, img_size + 1)

    # 1. CWT
    cfs, _ = pywt.cwt(segment, scales, 'cmor1.5-1.0')
    img = np.abs(cfs)

    # 2. Resize
    img_resized = resize(img, (img_size, img_size), mode='reflect', anti_aliasing=True)

    # 3. Normalize [0, 1]
    img_norm = (img_resized - img_resized.min()) / (img_resized.max() - img_resized.min() + 1e-8)

    # 4. Convert to torch tensor [1, 1, H, W]
    img_tensor = torch.from_numpy(img_norm[None, None, ...]).float().to(device)

    # 5. Apply FFDNet
    sigma = torch.tensor([[25 / 255.]], dtype=img_tensor.dtype, device=device).view(1, 1, 1, 1)
    with torch.no_grad():
        noise_pred = model(img_tensor, sigma)
        denoised = img_tensor - noise_pred

    # 6. Convert to uint8 image
    out_img = denoised.squeeze().cpu().numpy()
    out_img = np.clip(out_img, 0, 1)
    img_uint8 = (out_img * 255).astype(np.uint8)

    # 7. Sauvegarde
    pil_img = Image.fromarray(img_uint8, mode='L')

    test_id = test_path.replace('/', '_')  # ex: 'DS_WN_01'
    fname = f"segment_{index:03}.png"
    out_dir = os.path.join(output_base, split, classe, test_id, capteur)
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, fname)

    pil_img.save(out_path)

    return out_path  # retourne le chemin pour le CSV futur

le code complet pour appliquer ta fonction generate_cwt_image_ffdnet(...) √† tous les segments de segments_fbg.pkl, en respectant les splits train/val/test de split_segments.pkl.

Chaque image sera :

g√©n√©r√©e par CWT (cmor1.5-1.0)

d√©bruit√©e par FFDNet

sauvegard√©e dans /CWT_images/{split}/{classe}/{test}/{capteur}/segment_XXX.png

# Traitement global de tous les segments
import pickle

# 1. Charger les fichiers
with open("/content/drive/MyDrive/segments_fbg.pkl", "rb") as f:
    segments_fbg = pickle.load(f)

with open("/content/drive/MyDrive/split_segments.pkl", "rb") as f:
    split_segments = pickle.load(f)

# 2. Dossier de sortie
output_base = "/content/drive/MyDrive/CWT_images"

# 3. Appliquer la fonction √† chaque segment
total = 0
for classe, tests in segments_fbg.items():
    for test_path, capteurs in tests.items():
        for capteur, segments in capteurs.items():
            tags = split_segments[classe][test_path][capteur]

            for idx, segment in enumerate(segments):
                tag = tags[idx]  # train, val, test
                if tag not in ["train", "val", "test"]:
                    continue

                try:
                    path = generate_cwt_image_ffdnet(
                        segment=segment,
                        split=tag,
                        classe=classe,
                        test_path=test_path,
                        capteur=capteur,
                        index=idx,
                        output_base=output_base,
                        model=model,
                        device=device
                    )
                    total += 1
                    if total % 200 == 0:
                        print(f"{total} images g√©n√©r√©es...")

                except Exception as e:
                    print(f"Erreur : {classe} / {test_path} / {capteur} / segment {idx} ‚Üí {e}")

print(f" Termin√© : {total} images CWT d√©bruit√©es sauvegard√©es.")
"""

import os
from collections import defaultdict

base_dir = "/content/drive/MyDrive/CWT_images"
count_per_class = defaultdict(int)

# Parcours des dossiers
for split in os.listdir(base_dir):  # train, val, test
    split_path = os.path.join(base_dir, split)
    if not os.path.isdir(split_path):
        continue
    for classe in os.listdir(split_path):  # HS, DS_CTE, ...
        class_path = os.path.join(split_path, classe)
        for root, dirs, files in os.walk(class_path):
            for file in files:
                if file.endswith(".png"):
                    count_per_class[classe] += 1

# Affichage
print("üìä Nombre d‚Äôimages CWT g√©n√©r√©es par classe :")
for classe, count in count_per_class.items():
    print(f"  {classe:<10} : {count} images")

"""##  Fonction √©quivalente pour g√©n√©rer et sauvegarder les vecteurs SSI synchronis√©s

import os
import numpy as np
from scipy import signal
from scipy.linalg import svd, hankel, eig
import pickle

def generate_ssi_vector(segment, split, classe, test_path, capteur, index, output_base, fs=2048, decim=4, lags=40, ordre=20, top_k=10):

    Applique SSI sur un segment et sauvegarde le vecteur des top_k fr√©quences propres tri√©es.

    Args:
        segment (np.array): signal 1D du capteur (2048 pts)
        split (str): 'train', 'val', 'test'
        classe (str): 'HS', 'DS_CTE', etc.
        test_path (str): ex: 'DS_WN/01'
        capteur (str): ex: 'SW_FB2'
        index (int): num√©ro du segment
        output_base (str): dossier racine des .npy
        fs (int): fr√©quence d‚Äô√©chantillonnage brute
        decim (int): facteur de d√©cimation (r√©duction du bruit)
        lags (int): taille des fen√™tres (Hankel)
        ordre (int): ordre SSI
        top_k (int): nombre de fr√©quences √† garder

    # 1. D√©cimation
    segment_decim = signal.decimate(segment, decim, ftype='fir')
    fs_eff = fs // decim

    # 2. Construction de la matrice de Hankel
    N = len(segment_decim)
    hankel_matrix = np.zeros((lags, N - lags))
    for i in range(lags):
        hankel_matrix[i] = segment_decim[i:N - lags + i]

    # 3. SVD
    U, S, Vh = svd(hankel_matrix, full_matrices=False)
    U_r = U[:, :ordre]
    S_r = np.diag(S[:ordre])
    V_r = Vh[:ordre, :]

    # 4. Estimation de l‚Äôespace d‚Äô√©tat
    X = S_r @ V_r
    X1 = X[:, :-1]
    X2 = X[:, 1:]
    A_hat = X2 @ np.linalg.pinv(X1)

    # 5. Valeurs propres ‚Üí fr√©quences propres
    eigvals = np.linalg.eigvals(A_hat)
    freqs = np.abs(np.angle(eigvals) * fs_eff / (2 * np.pi))
    freqs = np.sort(freqs)[:top_k]

    # 6. Sauvegarde
    test_id = test_path.replace("/", "_")
    fname = f"segment_{index:03}.npy"
    out_dir = os.path.join(output_base, split, classe, test_id, capteur)
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, fname)
    np.save(out_path, freqs.astype(np.float32))

    return out_path  # pour CSV futur

# G√©n√©ration de tous les vecteurs SSI synchronis√©s
import pickle

# 1. Charger les fichiers n√©cessaires

with open("/content/drive/MyDrive/segments_fbg.pkl", "rb") as f:
    segments_fbg = pickle.load(f)

with open("/content/drive/MyDrive/split_segments.pkl", "rb") as f:
    split_segments = pickle.load(f)

# 2. Param√®tres
output_base = "/content/drive/MyDrive/SSI_vectors"
fs = 2048
decim = 4
lags = 40
ordre = 20
top_k = 10

# 3. Traitement de tous les segments
total = 0
for classe, tests in segments_fbg.items():
    for test_path, capteurs in tests.items():
        for capteur, segments in capteurs.items():
            tags = split_segments[classe][test_path][capteur]

            for idx, segment in enumerate(segments):
                tag = tags[idx]
                if tag not in ["train", "val", "test"]:
                    continue

                try:
                    ssi_path = generate_ssi_vector(
                        segment=segment,
                        split=tag,
                        classe=classe,
                        test_path=test_path,
                        capteur=capteur,
                        index=idx,
                        output_base=output_base,
                        fs=fs,
                        decim=decim,
                        lags=lags,
                        ordre=ordre,
                        top_k=top_k
                    )
                    total += 1
                    if total % 200 == 0:
                        print(f" {total} vecteurs SSI g√©n√©r√©s...")

                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur : {classe}/{test_path}/{capteur}/segment {idx} ‚Üí {e}")

print(f" Termin√© : {total} vecteurs SSI sauvegard√©s.")

## G√©n√©ration du CSV de correspondance

import os
import pandas as pd

# Dossiers racine
cwt_root = "/content/drive/MyDrive/CWT_images"
ssi_root = "/content/drive/MyDrive/SSI_vectors"

rows = []

# Parcours des splits
for split in ["train", "val", "test"]:
    cwt_split_dir = os.path.join(cwt_root, split)
    ssi_split_dir = os.path.join(ssi_root, split)

    for classe in os.listdir(cwt_split_dir):
        cwt_class_dir = os.path.join(cwt_split_dir, classe)
        ssi_class_dir = os.path.join(ssi_split_dir, classe)

        for test_id in os.listdir(cwt_class_dir):
            cwt_test_dir = os.path.join(cwt_class_dir, test_id)
            ssi_test_dir = os.path.join(ssi_class_dir, test_id)

            for capteur in os.listdir(cwt_test_dir):
                cwt_capteur_dir = os.path.join(cwt_test_dir, capteur)
                ssi_capteur_dir = os.path.join(ssi_test_dir, capteur)

                if not os.path.isdir(ssi_capteur_dir):
                    continue  # √©viter erreurs si SSI non g√©n√©r√©

                for fname in sorted(os.listdir(cwt_capteur_dir)):
                    if fname.endswith(".png"):
                        image_path = os.path.join(cwt_capteur_dir, fname)
                        ssi_path = os.path.join(ssi_capteur_dir, fname.replace(".png", ".npy"))

                        if os.path.exists(ssi_path):
                            rows.append({
                                "image_path": image_path,
                                "ssi_path": ssi_path,
                                "label": classe,
                                "split": split
                            })

print(f"‚úÖ Total segments coupl√©s trouv√©s : {len(rows)}")

# Enregistrer le CSV
df = pd.DataFrame(rows)
csv_path = "/content/drive/MyDrive/ssi_cwt_dataset.csv"
df.to_csv(csv_path, index=False)

print(f"‚úÖ CSV sauvegard√© : {csv_path}")
"""

import pandas as pd

# Charger le fichier CSV
csv_path = "/content/drive/MyDrive/ssi_cwt_dataset.csv"
df = pd.read_csv(csv_path)

# üîç Afficher les 5 premi√®res lignes
print("üîπ Aper√ßu des premi√®res lignes :")
print(df.head())

# üìä Informations g√©n√©rales
print("\nüîπ Informations g√©n√©rales :")
print(df.info())

# üè∑Ô∏è Valeurs uniques dans 'label' et 'split'
print("\nüîπ Classes (label) disponibles :", df['label'].unique())
print("üîπ R√©partition des splits :")
print(df['split'].value_counts())

# üìà Nombre de segments par classe
print("\nüîπ Nombre d‚Äô√©l√©ments par classe :")
print(df['label'].value_counts())

# Diagramme SSI (FB10, Segment 20, toutes classes)
import os
import numpy as np
import matplotlib.pyplot as plt

# === Param√®tres ===
base_dir = "/content/drive/MyDrive/SSI_vectors"
split = "train"
target_sensor = "SW_FB9"
target_segment = "segment_020.npy"   # segment recherch√©
orders = np.arange(2, 41, 2)        # ordres du mod√®le SSI
fmin, fmax = 0, 100                  # bande fr√©quentielle √† afficher (Hz)

# Couleurs par classe
colors = {
    'HS': 'C0',
    'DS_CTE': 'C1',
    'DS_RLE': 'C2',
    'DS_TLE': 'C3'
}

plt.figure(figsize=(10, 6))

for classe in ["HS", "DS_CTE", "DS_RLE", "DS_TLE"]:
    classe_path = os.path.join(base_dir, split, classe)
    if not os.path.isdir(classe_path):
        continue

    # Parcours des sous-dossiers (tests)
    for test in os.listdir(classe_path):
        sensor_path = os.path.join(classe_path, test, target_sensor)
        if not os.path.isdir(sensor_path):
            continue

        file_path = os.path.join(sensor_path, target_segment)
        if os.path.isfile(file_path):
            # Charger les fr√©quences SSI
            ssi_vector = np.load(file_path)
            # V√©rifier la taille
            top_k = min(len(orders), len(ssi_vector))
            freqs = ssi_vector[:top_k]
            plt.scatter(orders[:top_k], freqs,
                        color=colors[classe],
                        alpha=0.7, s=30, label=classe)
            break  # on prend un seul test par classe pour √©viter les doublons

# Configuration du graphique
handles, labels = plt.gca().get_legend_handles_labels()
unique = dict(zip(labels, handles))
plt.legend(unique.values(), unique.keys())

plt.xlabel("Ordre du mod√®le SSI")
plt.ylabel("Fr√©quences propres (Hz)")
plt.title(f"Diagramme SSI ‚Äì Capteur {target_sensor} ‚Äì Segment 20 ‚Äì Split {split}")
plt.ylim([fmin, fmax])
plt.grid(True, alpha=0.4)
plt.tight_layout()
plt.show()

import os
import numpy as np
import pandas as pd

# === Param√®tres ===
base_dir = "/content/drive/MyDrive/SSI_vectors"
split = "train"
target_sensor = "SW_FB9"
target_segment = "segment_020.npy"
orders = np.arange(2, 41, 2)
classes = ["HS", "DS_CTE", "DS_RLE", "DS_TLE"]

# Stockage des donn√©es
data_rows = []

for cls in classes:
    cls_path = os.path.join(base_dir, split, cls)
    if not os.path.isdir(cls_path):
        continue

    for test in os.listdir(cls_path):
        sensor_path = os.path.join(cls_path, test, target_sensor)
        file_path = os.path.join(sensor_path, target_segment)
        if os.path.isfile(file_path):
            freqs = np.load(file_path)
            # R√©cup√®re top_k valeurs correspondant aux ordres SSI
            top_k = min(len(freqs), len(orders))
            for i in range(top_k):
                data_rows.append([cls, orders[i], freqs[i]])
            break  # un seul test par classe

# Conversion en DataFrame
df = pd.DataFrame(data_rows, columns=["Classe", "Ordre_SSI", "Frequence_Hz"])

# Tableau pivot√© (Ordres en ligne, classes en colonnes)
tableau = df.pivot(index="Ordre_SSI", columns="Classe", values="Frequence_Hz")

print("=== Tableau des fr√©quences SSI pour FB10 - Segment 20 ===")
print(tableau)

# Sauvegarde en CSV si besoin
tableau.to_csv("tableau_SSI_FB_segment20.csv")

import os
import numpy as np
import pandas as pd
from itertools import combinations

# === Param√®tres ===
base_dir = "/content/drive/MyDrive/SSI_vectors"
split = "train"
target_segment = "segment_020.npy"   # segment √† analyser
classes = ["DS_CTE", "DS_RLE", "DS_TLE"]
capteurs = [f"SW_FB{i}" for i in range(1, 11)]  # FB1 √† FB10
orders = np.arange(2, 41, 2)  # Ordres SSI

# === Fonction pour lire une fr√©quence pour un capteur et une classe ===
def lire_frequences(classe, capteur):
    classe_path = os.path.join(base_dir, split, classe)
    if not os.path.isdir(classe_path):
        return None

    for test in os.listdir(classe_path):
        file_path = os.path.join(classe_path, test, capteur, target_segment)
        if os.path.isfile(file_path):
            freqs = np.load(file_path)
            return freqs
    return None

# === Stockage des r√©sultats discriminants ===
rows = []

for capteur in capteurs:
    # Charger les fr√©quences pour chaque classe
    freq_data = {}
    for cls in classes:
        freqs = lire_frequences(cls, capteur)
        if freqs is not None:
            freq_data[cls] = freqs
        else:
            freq_data[cls] = np.zeros(len(orders))

    # Comparer les √©carts entre chaque paire de classes
    for i, ordre in enumerate(orders):
        # valeurs par classe √† cet ordre
        vals = {cls: freq_data[cls][i] if i < len(freq_data[cls]) else 0 for cls in classes}

        # calcul des √©carts absolus entre chaque paire
        diff_pairs = []
        for (cls1, cls2) in combinations(classes, 2):
            diff_pairs.append(abs(vals[cls1] - vals[cls2]))

        # moyenne des √©carts
        ecart_moyen = np.mean(diff_pairs)

        rows.append([capteur, ordre, ecart_moyen])

# === DataFrame r√©sultat ===
df_discriminant = pd.DataFrame(rows, columns=["Capteur", "Ordre_SSI", "Ecart_moyen_Hz"])

# Pivot pour tableau (capteur en ligne, ordre en colonne)
tableau = df_discriminant.pivot(index="Capteur", columns="Ordre_SSI", values="Ecart_moyen_Hz")

print("=== Tableau discriminatoire multi-capteurs (moyenne des √©carts Hz entre DS_CTE, DS_RLE, DS_TLE) ===")
print(tableau)

# Sauvegarde en CSV
output_path = "tableau_discriminant_multicapteurs.csv"
tableau.to_csv(output_path)
print(f"\n‚úÖ R√©sultats sauvegard√©s dans {output_path}")

import pandas as pd

# Exemple : ton tableau de r√©sultats (DataFrame 'tableau')
# tableau = df_discriminant.pivot(index="Capteur", columns="Ordre_SSI", values="Ecart_moyen_Hz")

# D√©finir seuil de discrimination (Hz)
SEUIL = 5.0

# Nombre total de combinaisons
total = tableau.size

# Nombre de cas o√π l'√©cart est jug√© discriminant
discriminants = (tableau > SEUIL).sum().sum()

# Pouvoir de discrimination global
pouvoir_global = (discriminants / total) * 100

print(f"‚úÖ Pouvoir global de discrimination pour le segment 20 : {pouvoir_global:.2f}%")

import os
import numpy as np
import pandas as pd
from itertools import combinations
import matplotlib.pyplot as plt
import seaborn as sns

# === Param√®tres ===
base_dir = "/content/drive/MyDrive/SSI_vectors"
split = "train"
segments = [f"segment_{i:03d}.npy" for i in range(72)]
classes = ["DS_CTE", "DS_RLE", "DS_TLE"]
capteurs = [f"SW_FB{i}" for i in range(1, 11)]
orders = np.arange(2, 41, 2)
SEUIL = 5.0
TOP_N = 20

rows = []

# --- 1) Parcours de tous les segments / capteurs / ordres ---
for seg in segments:
    for capteur in capteurs:
        freq_data = {}
        for cls in classes:
            found = False
            cls_path = os.path.join(base_dir, split, cls)
            if os.path.isdir(cls_path):
                for test in os.listdir(cls_path):
                    file_path = os.path.join(cls_path, test, capteur, seg)
                    if os.path.isfile(file_path):
                        freq_data[cls] = np.load(file_path)
                        found = True
                        break
            if not found:
                freq_data[cls] = np.zeros(len(orders))

        for i, ordre in enumerate(orders):
            vals = {cls: freq_data[cls][i] if i < len(freq_data[cls]) else 0 for cls in classes}
            diffs = [abs(vals[c1] - vals[c2]) for c1, c2 in combinations(classes, 2)]
            rows.append([seg, capteur, ordre, np.mean(diffs)])

df = pd.DataFrame(rows, columns=["Segment", "Capteur", "Ordre_SSI", "Ecart_moyen_Hz"])

# --- 2) Moyenne globale par capteur et par ordre ---
df_capteur = df.groupby("Capteur")["Ecart_moyen_Hz"].mean().sort_values(ascending=False)
df_ordre = df.groupby("Ordre_SSI")["Ecart_moyen_Hz"].mean().sort_values(ascending=False)

# --- 3) S√©lection top N couples capteur-ordre ---
df_mean = df.groupby(["Capteur", "Ordre_SSI"])["Ecart_moyen_Hz"].mean().reset_index()
top_features = df_mean[df_mean["Ecart_moyen_Hz"] >= SEUIL].sort_values(by="Ecart_moyen_Hz", ascending=False)
top_features = top_features.head(TOP_N)

# --- 4) Tableau heatmap pour visualiser la discrimination ---
pivot_table = df_mean.pivot(index="Capteur", columns="Ordre_SSI", values="Ecart_moyen_Hz")
plt.figure(figsize=(14, 6))
sns.heatmap(pivot_table, cmap="YlOrRd", annot=False, cbar_kws={'label': 'Ecart moyen (Hz)'})
plt.title("Heatmap - Pouvoir discriminant des capteurs vs ordres SSI")
plt.xlabel("Ordre SSI")
plt.ylabel("Capteur")
plt.tight_layout()
plt.show()

# --- 5) R√©sultats ---
print("\n=== Pouvoir global de discrimination par capteur (Hz) ===")
print(df_capteur)

print("\n=== Pouvoir global de discrimination par ordre SSI (Hz) ===")
print(df_ordre)

print(f"\n=== Top {TOP_N} couples (capteur, ordre SSI) discriminants (Ecart ‚â• {SEUIL} Hz) ===")
print(top_features)

# --- 6) Sauvegarde en CSV ---
df_capteur.to_csv("pouvoir_discriminant_capteur.csv")
df_ordre.to_csv("pouvoir_discriminant_ordre.csv")
top_features.to_csv("top_features_SSI_selectionnees.csv", index=False)
print("\n‚úÖ R√©sultats sauvegard√©s :\n- pouvoir_discriminant_capteur.csv\n- pouvoir_discriminant_ordre.csv\n- top_features_SSI_selectionnees.csv")

"""
from google.colab import drive
import os
import shutil

# 1Ô∏è‚É£ Monter ton Google Drive
drive.mount('/content/drive')

# 2Ô∏è‚É£ Dossier de destination
destination_folder = '/content/drive/MyDrive/SSI_Analysis_Results'
os.makedirs(destination_folder, exist_ok=True)

# 3Ô∏è‚É£ Liste des fichiers √† d√©placer
fichiers = [
    "pouvoir_discriminant_capteur.csv",
    "pouvoir_discriminant_ordre.csv",
    "tableau_SSI_FB10_segment20.csv",
    "tableau_discriminant_multicapteur.csv",
    "top_features_SSI_selectionnees.csv"
]

# 4Ô∏è‚É£ Copie dans le dossier
for fichier in fichiers:
    if os.path.exists(fichier):
        shutil.copy(fichier, destination_folder)
        print(f"‚úÖ {fichier} sauvegard√© dans {destination_folder}")
    else:
        print(f"‚ö†Ô∏è {fichier} introuvable dans le r√©pertoire courant.")

print("\nüìÇ Tous les fichiers disponibles dans ton Google Drive -> 'SSI_Analysis_Results'")
"""

!ls -lh | grep tableau_discriminant

"""import shutil

source = "tableau_discriminant_multicapteurs.csv"
destination = "/content/drive/MyDrive/SSI_Analysis_Results/tableau_discriminant_multicapteurs.csv"

shutil.copy(source, destination)
print(" Fichier 'tableau_discriminant_multicapteurs.csv' sauvegard√© dans ton Google Drive")

## Pond√©ration SSI multi-capteurs
"""

import os
import numpy as np
import pandas as pd

# === PARAM√àTRES ===
base_dir = "/content/drive/MyDrive/SSI_vectors"
tableau_path = "/content/drive/MyDrive/SSI_Analysis_Results/tableau_discriminant_multicapteurs.csv"
output_suffix = "_weighted"
orders_all = np.arange(2, 41, 2)

# Charger le tableau discriminant
df = pd.read_csv(tableau_path)
df_long = df.melt(id_vars=["Capteur"], var_name="Ordre_SSI", value_name="Ecart_moyen_Hz")
df_long["Ordre_SSI"] = df_long["Ordre_SSI"].astype(int)

max_val = df_long["Ecart_moyen_Hz"].max()
df_long["Poids"] = df_long["Ecart_moyen_Hz"] / max_val

weights = {(row["Capteur"], int(row["Ordre_SSI"])): row["Poids"] for _, row in df_long.iterrows()}

print(f"Table des poids pr√©par√©e : {len(weights)} combinaisons capteur-ordre.")

# === Fonction pond√©ration adapt√©e ===
def appliquer_poids(freqs, capteur):
    freqs_pond = []
    n = len(freqs)
    for i in range(n):
        ordre = orders_all[i] if i < len(orders_all) else None
        if ordre is not None:
            w = weights.get((capteur, int(ordre)), 0.0)
        else:
            w = 0.0
        freqs_pond.append(freqs[i] * w)
    return np.array(freqs_pond)

# === Parcours complet ===
for split in ["train", "val", "test"]:
    for root, dirs, files in os.walk(os.path.join(base_dir, split)):
        for file in files:
            if file.endswith(".npy") and not file.endswith(f"{output_suffix}.npy"):
                file_path = os.path.join(root, file)
                capteur = os.path.basename(os.path.dirname(file_path))
                try:
                    freqs = np.load(file_path)
                    freqs_w = appliquer_poids(freqs, capteur)
                    output_path = file_path.replace(".npy", f"{output_suffix}.npy")
                    np.save(output_path, freqs_w)
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur sur {file_path}: {e}")

print("\n Pond√©ration appliqu√©e √† tous les fichiers SSI (taille variable g√©r√©e).")

"""## Cr√©ation du CSV fusion pond√©r√©"""

import os
import pandas as pd

# === PARAM√àTRES ===
base_images = "/content/drive/MyDrive/CWT_images"
base_ssi = "/content/drive/MyDrive/SSI_vectors"
output_csv = "/content/drive/MyDrive/dataset_fusion_weighted.csv"

splits = ["train", "val", "test"]
classes = ["HS", "DS_CTE", "DS_RLE", "DS_TLE"]

rows = []

# === Parcours de l'ensemble du dataset ===
for split in splits:
    for cls in classes:
        img_dir = os.path.join(base_images, split, cls)
        ssi_dir = os.path.join(base_ssi, split, cls)

        if not os.path.exists(img_dir) or not os.path.exists(ssi_dir):
            continue

        for test in os.listdir(img_dir):
            test_img_path = os.path.join(img_dir, test)
            test_ssi_path = os.path.join(ssi_dir, test)

            if not os.path.isdir(test_img_path) or not os.path.isdir(test_ssi_path):
                continue

            # Parcourir les capteurs
            for capteur in os.listdir(test_img_path):
                img_capteur_path = os.path.join(test_img_path, capteur)
                ssi_capteur_path = os.path.join(test_ssi_path, capteur)

                if not os.path.isdir(img_capteur_path) or not os.path.isdir(ssi_capteur_path):
                    continue

                # Lister tous les segments
                for seg_file in os.listdir(img_capteur_path):
                    if not seg_file.endswith(".png"):
                        continue

                    # Chemins complets image / SSI
                    img_path = os.path.join(img_capteur_path, seg_file)
                    ssi_file = seg_file.replace(".png", "_weighted.npy")
                    ssi_path = os.path.join(ssi_capteur_path, ssi_file)

                    # V√©rifier l'existence du fichier SSI pond√©r√©
                    if os.path.isfile(ssi_path):
                        rows.append([img_path, ssi_path, cls, split])
                    else:
                        # Si fichier pond√©r√© manquant, ignorer
                        pass

# === Cr√©ation du DataFrame final ===
df = pd.DataFrame(rows, columns=["image_path", "ssi_path", "label", "split"])

# Sauvegarde CSV
df.to_csv(output_csv, index=False)
print(f"‚úÖ CSV final cr√©√© : {output_csv}")
print(f"Nombre total de lignes : {len(df)}")

import pandas as pd
import os

# === Param√®tre : chemin de ton fichier CSV fusionn√© ===
csv_path = "/content/drive/MyDrive/dataset_fusion_weighted.csv"

# V√©rifier l'existence du fichier
if os.path.exists(csv_path):
    print(f"‚úÖ Fichier trouv√© : {csv_path}")

    # Charger le fichier CSV
    df = pd.read_csv(csv_path)

    # Afficher quelques infos
    print("\nüìä Informations g√©n√©rales :")
    print(f"- Nombre total de lignes : {len(df)}")
    print(f"- Colonnes : {list(df.columns)}")

    # Aper√ßu des 5 premi√®res lignes
    print("\nüîπ Aper√ßu (5 premi√®res lignes) :")
    display(df.head())

    # Aper√ßu al√©atoire de 5 lignes
    print("\nüé≤ Aper√ßu al√©atoire (5 lignes) :")
    display(df.sample(5))
else:
    print(f"‚ùå Fichier introuvable : {csv_path}")

"""## Dataset PyTorch ‚Äì FusionDataset"""

import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np
import pandas as pd
import torchvision.transforms as T

class FusionDataset(Dataset):
    def __init__(self, csv_path, split="train", transform=None, label_map=None):
        """
        Args:
            csv_path (str): Chemin du fichier CSV fusionn√© (image, SSI, label, split)
            split (str): 'train', 'val' ou 'test'
            transform (torchvision.transforms): Transformations appliqu√©es aux images
            label_map (dict): Mapping label -> entier (ex {'HS':0, 'DS_CTE':1, ...})
        """
        self.data = pd.read_csv(csv_path)
        self.data = self.data[self.data["split"] == split].reset_index(drop=True)
        self.transform = transform

        if label_map is None:
            classes = sorted(self.data["label"].unique())
            self.label_map = {cls: idx for idx, cls in enumerate(classes)}
        else:
            self.label_map = label_map

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        image_path = row["image_path"]
        ssi_path = row["ssi_path"]
        label = self.label_map[row["label"]]

        # Chargement image
        image = Image.open(image_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        else:
            image = T.ToTensor()(image)

        # Chargement SSI pond√©r√©
        ssi_vector = np.load(ssi_path)
        ssi_vector = torch.tensor(ssi_vector, dtype=torch.float32)

        return image, ssi_vector, torch.tensor(label, dtype=torch.long)

# D√©finir le chemin o√π sauvegarder ton fichier
file_path = "/content/drive/MyDrive/fusion_dataset.py"

code = """
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np
import pandas as pd
import torchvision.transforms as T

class FusionDataset(Dataset):
    def __init__(self, csv_path, split='train', transform=None, label_map=None):
        '''
        Dataset personnalis√© pour charger les donn√©es fusionn√©es Image + SSI pond√©r√©.

        Args:
            csv_path (str): Chemin du fichier CSV fusionn√©
            split (str): 'train', 'val' ou 'test'
            transform (torchvision.transforms): Transformations appliqu√©es aux images
            label_map (dict): Mapping optionnel des labels -> entiers
        '''
        self.data = pd.read_csv(csv_path)
        self.data = self.data[self.data['split'] == split].reset_index(drop=True)
        self.transform = transform

        if label_map is None:
            classes = sorted(self.data['label'].unique())
            self.label_map = {cls: idx for idx, cls in enumerate(classes)}
        else:
            self.label_map = label_map

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]

        # Chargement image
        image = Image.open(row['image_path']).convert('RGB')
        if self.transform:
            image = self.transform(image)
        else:
            image = T.ToTensor()(image)

        # Chargement SSI pond√©r√©
        ssi_vector = np.load(row['ssi_path'])
        ssi_vector = torch.tensor(ssi_vector, dtype=torch.float32)

        # Label encod√©
        label = torch.tensor(self.label_map[row['label']], dtype=torch.long)

        return image, ssi_vector, label
"""

# Sauvegarde du fichier dans ton Drive
with open(file_path, "w") as f:
    f.write(code)

print(f"‚úÖ Fichier 'fusion_dataset.py' sauvegard√© dans : {file_path}")

# Importer ton module
import sys
sys.path.append("/content/drive/MyDrive")

from fusion_dataset import FusionDataset

"""‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Signal brut (FBG)       ‚îÇ  (1 sec / capteur)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Pr√©traitement      ‚îÇ
   ‚îÇ - Nettoyage        ‚îÇ
   ‚îÇ - D√©coupage        ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ                  ‚îÇ
      ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CWT + FFDNet‚îÇ   ‚îÇ SSI (Stochastic     ‚îÇ
‚îÇ (scalogram) ‚îÇ   ‚îÇ Subspace ID)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                     ‚îÇ
       ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Image 224x224 ‚îÇ     ‚îÇ Vecteur SSI   ‚îÇ
‚îÇ (temps-fr√©q)  ‚îÇ     ‚îÇ top_k=10 freq ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                      ‚îÇ
       ‚ñº                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Normalisation‚îÇ       ‚îÇ Pond√©ration       ‚îÇ
‚îÇ + Augmentation‚îÇ      ‚îÇ (poids capteur/   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ ordre SSI)       ‚îÇ
       ‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Branche Swin ‚îÇ            ‚îÇ Branche MLP   ‚îÇ
‚îÇ Transformer  ‚îÇ            ‚îÇ (64 ‚Üí 32 dims)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                              ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Fusion tardive‚îÇ
        ‚îÇ [concat]      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Fully Connected‚îÇ
        ‚îÇ (classification‚îÇ
        ‚îÇ  4 classes)    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  Pr√©diction    ‚îÇ
        ‚îÇ HS / DS_CTE /  ‚îÇ
        ‚îÇ DS_RLE / DS_TLE‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Signal brut (FBG)            ‚îÇ   [B, N_capteurs, 2048]
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Pr√©traitement            ‚îÇ
   ‚îÇ - Nettoyage              ‚îÇ
   ‚îÇ - D√©coupage 1s           ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                   ‚îÇ
        ‚ñº                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CWT             ‚îÇ   ‚îÇ SSI (Stochastic     ‚îÇ
‚îÇ Scalogram       ‚îÇ   ‚îÇ Subspace ID)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                         ‚îÇ
        ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Image temps-fr√©quence    ‚îÇ   ‚îÇ Top_k=10 fr√©quences ‚îÇ
‚îÇ (3 canaux RGB)           ‚îÇ   ‚îÇ [B, N_capteurs, 10] ‚îÇ
‚îÇ [B, 3, 224, 224]         ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
          ‚ñº                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Swin-Tiny Backbone         ‚îÇ   ‚îÇ MLP R√©duction dim.      ‚îÇ
‚îÇ (patch embed + 4 stages)   ‚îÇ   ‚îÇ Entr√©e : [B, N*10]=64   ‚îÇ
‚îÇ Sortie : [B, 768, 7, 7]    ‚îÇ   ‚îÇ Sortie : [B, 32]        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚ñº                                ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
   ‚îÇ CBAM Attention Module  ‚îÇ                ‚îÇ
   ‚îÇ (Channel+Spatial)      ‚îÇ                ‚îÇ
   ‚îÇ Entr√©e: [B, 768, 7, 7] ‚îÇ                ‚îÇ
   ‚îÇ Sortie: [B, 768, 7, 7] ‚îÇ                ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
               ‚ñº                             ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Adaptive Avg Pooling   ‚îÇ        ‚îÇ Vecteur SSI r√©duit‚îÇ
   ‚îÇ [B, 768, 7, 7] ‚Üí [B,768‚îÇ        ‚îÇ [B, 32]           ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                                ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñº
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ Fusion tardive [Concat]       ‚îÇ
                 ‚îÇ [B, 768] ‚äï [B, 32] ‚Üí [B, 800] ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚ñº
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ Fully Connected Layer         ‚îÇ
                 ‚îÇ [B, 800] ‚Üí [B, 4] (softmax)   ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚ñº
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ Pr√©diction finale             ‚îÇ
                 ‚îÇ HS / DS_CTE / DS_RLE / DS_TLE ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

## √âtape 1 ‚Äì Nouveau fichier swin.py
"""

import timm
import torch
from torch import nn
from .cbam import CBAM

class SSI_SwinFusionNet(nn.Module):
    """
    Mod√®le fusion tardive :
    - Branche image : Swin Tiny + CBAM
    - Branche SSI : MLP (vecteurs SSI)
    - Fusion tardive -> classification
    """
    def __init__(self, num_classes=4, ssi_input_dim=64, pretrained=True):
        super(SSI_SwinFusionNet, self).__init__()

        # === Branche image (Swin + CBAM) ===
        self.backbone = timm.create_model(
            'swin_tiny_patch4_window7_224',
            pretrained=pretrained,
            num_classes=0,        # pas de t√™te FC
            global_pool=""
        )
        self.cbam = CBAM(self.backbone.num_features)
        self.pool = nn.AdaptiveAvgPool2d(1)

        # === Branche SSI ===
        self.ssi_mlp = nn.Sequential(
            nn.Linear(ssi_input_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU()
        )

        # === Fusion tardive ===
        fusion_dim = self.backbone.num_features + 32  # 768 + 32
        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )

        self.num_classes = num_classes

    def forward(self, img, ssi):
        # Branche image
        x = self.backbone.forward_features(img)   # [B, 768, 7, 7]
        x = self.cbam(x)
        x = self.pool(x)
        x = torch.flatten(x, 1)                   # [B, 768]

        # Branche SSI
        ssi_feat = self.ssi_mlp(ssi)              # [B, 32]

        # Fusion tardive
        fused = torch.cat([x, ssi_feat], dim=1)   # [B, 800]
        out = self.classifier(fused)              # [B, num_classes]
        return out

!apt-get install git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/MonProjet_SSI_Swin

!git config --global user.email "softwesternmtl@gmail.com"
!git config --global user.name "soft2025"

!git init
!git add .
!git commit -m "Initial commit depuis Colab"
!git branch -M main
!git remote add origin https://github.com/soft2025/SSI_Swin_Fusion.git
!git push -u origin main

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/MonProjet_SSI_Swin

!git remote -v

!git remote remove origin
!git remote add origin https://github.com/TonNomUtilisateur/SSI_Swin_Fusion.git
!git add .
!git commit -m "Initial commit"
!git branch -M main
!git push -u origin main

